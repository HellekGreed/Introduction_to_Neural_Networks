{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "PH_mcB21EoxE"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "bJQINrKnDqju"
      },
      "outputs": [],
      "source": [
        "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    text = text.replace('\\ufeff', '') # убираем первый невидимый символ\n",
        "    text = re.sub(r'[^А-я ]', '', text) # убираем все недопустимые символы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SubXLsi5ErEN",
        "outputId": "005d9a4b-3e24-4e7e-e757-f54d98060e02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Вы  лучший ответ на проблемы которые возникли в понедельникДумайте позитивно и верьте в свою способность достигать отличных результатовЕсли вы смогли в понедельник подняться с постели значит вы супер герой'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 251
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyD7g4glKVps",
        "outputId": "c99ae975-87fd-4459-b12d-964c1f0de183"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "IJD76YJ4E6z0"
      },
      "outputs": [],
      "source": [
        "num_characters = 34 #33 буквы + пробел"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "DgiJrgsiIK_x"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "appv1wfpIJvH"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=num_characters, char_level=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "N1yoi7pGId-n"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJmXPaQbIf-I",
        "outputId": "848b6b3b-fac5-4130-fb5d-33b422e9888a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, 'о': 2, 'т': 3, 'е': 4, 'и': 5, 'в': 6, 'н': 7, 'с': 8, 'л': 9, 'п': 10, 'ь': 11, 'ы': 12, 'р': 13, 'а': 14, 'д': 15, 'у': 16, 'к': 17, 'з': 18, 'ч': 19, 'й': 20, 'м': 21, 'г': 22, 'б': 23, 'я': 24, 'ш': 25, 'ю': 26, 'х': 27}\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "1wWs_206JRu-"
      },
      "outputs": [],
      "source": [
        "inp_chars = 6 #\n",
        "data = tokenizer.texts_to_matrix(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqy7uBYCJTYV",
        "outputId": "25501e48-beb7-41cd-aa91-e19bd030f6af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ],
      "source": [
        "data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnWQb42jKAd1",
        "outputId": "81a4af3a-1d6c-4acc-e09b-387f31c46882"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 260
        }
      ],
      "source": [
        "n = data.shape[0]-inp_chars\n",
        "n  #размер обучающего множества"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "kvZ-iB9LKwgc"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "_nG7M5RIKsfs"
      },
      "outputs": [],
      "source": [
        "X = np.array([data[i:i+inp_chars, :] for i in range(n)])\n",
        "Y = data[inp_chars:] #предсказание следующего символа"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z20DCMmSK3tj",
        "outputId": "84255ec2-6955-4c7b-cccf-681d4b629e89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ],
      "source": [
        "len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NrELysIK5fL",
        "outputId": "a4b283b8-4777-4e84-ef3e-b44768bca00f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbsyrcEGK7G7",
        "outputId": "c71f2fa9-b1a0-4930-936c-24a9aafb3f42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 265
        }
      ],
      "source": [
        "Y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "lIP7yhRzLZsr"
      },
      "outputs": [],
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "gwyYcqGiLXPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc20d61-5874-47c4-e2b4-5965795a69d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_15 (SimpleRNN)   (None, 500)               267500    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 34)                17034     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 284534 (1.09 MB)\n",
            "Trainable params: 284534 (1.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Input((inp_chars, num_characters)))\n",
        "model.add(SimpleRNN(500, activation='tanh'))\n",
        "model.add(Dense(num_characters, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3-y2cQiMGLK",
        "outputId": "6ade06f4-b7c9-47fd-a162-bc9c7501897a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 11ms/step - loss: 3.3905 - accuracy: 0.0804\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 2.3783 - accuracy: 0.3518\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 1.9062 - accuracy: 0.4824\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 1.5069 - accuracy: 0.5075\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.2186 - accuracy: 0.6332\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 1.0069 - accuracy: 0.6935\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.9115 - accuracy: 0.7538\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.7625 - accuracy: 0.8090\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6546 - accuracy: 0.8191\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5753 - accuracy: 0.8543\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5010 - accuracy: 0.8794\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4621 - accuracy: 0.9095\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4108 - accuracy: 0.9045\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3711 - accuracy: 0.9196\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3840 - accuracy: 0.8945\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3525 - accuracy: 0.9146\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2963 - accuracy: 0.9246\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.2531 - accuracy: 0.9648\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2069 - accuracy: 0.9648\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1943 - accuracy: 0.9648\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2030 - accuracy: 0.9698\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2161 - accuracy: 0.9548\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1450 - accuracy: 0.9799\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2176 - accuracy: 0.9548\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1926 - accuracy: 0.9598\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1920 - accuracy: 0.9548\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3212 - accuracy: 0.9397\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2954 - accuracy: 0.9347\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2388 - accuracy: 0.9548\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1610 - accuracy: 0.9749\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1932 - accuracy: 0.9598\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1730 - accuracy: 0.9648\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1299 - accuracy: 0.9698\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2192 - accuracy: 0.9749\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1922 - accuracy: 0.9648\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1347 - accuracy: 0.9799\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1148 - accuracy: 0.9749\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0840 - accuracy: 0.9799\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0733 - accuracy: 0.9849\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1076 - accuracy: 0.9698\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0758 - accuracy: 0.9849\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0825 - accuracy: 0.9749\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0943 - accuracy: 0.9799\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0747 - accuracy: 0.9950\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0640 - accuracy: 0.9849\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0536 - accuracy: 0.9849\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0446 - accuracy: 0.9950\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0577 - accuracy: 0.9899\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0386 - accuracy: 0.9950\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0475 - accuracy: 0.9849\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0443 - accuracy: 0.9899\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0475 - accuracy: 0.9849\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1031 - accuracy: 0.9749\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0864 - accuracy: 0.9698\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1120 - accuracy: 0.9598\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1527 - accuracy: 0.9648\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1371 - accuracy: 0.9799\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1148 - accuracy: 0.9799\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0473 - accuracy: 0.9849\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0593 - accuracy: 0.9899\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0730 - accuracy: 0.9849\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0629 - accuracy: 0.9799\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0540 - accuracy: 0.9849\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0403 - accuracy: 0.9899\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0321 - accuracy: 0.9899\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0322 - accuracy: 0.9899\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0463 - accuracy: 0.9899\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0389 - accuracy: 0.9849\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0225 - accuracy: 0.9950\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0277 - accuracy: 0.9849\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9899\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9950\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0249 - accuracy: 0.9849\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9950\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9950\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 0.9849\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9950\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9950\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0482 - accuracy: 0.9950\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0492 - accuracy: 0.9950\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0401 - accuracy: 0.9950\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9950\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0202 - accuracy: 0.9899\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0190 - accuracy: 0.9950\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9899\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9950\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9899\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9950\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9950\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9899\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9950\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0158 - accuracy: 0.9950\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0158 - accuracy: 0.9950\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9950\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 0.9899\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9950\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9849\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 0.9899\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9950\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "history = model.fit(X, Y, batch_size=32, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "s0_LNL2pMiku"
      },
      "outputs": [],
      "source": [
        "def buildPhrase(inp_str, str_len = 50):\n",
        "  for i in range(str_len):\n",
        "    x = []\n",
        "    for j in range(i, i+inp_chars):\n",
        "      x.append(tokenizer.texts_to_matrix(inp_str[j])) # преобразуем символы в One-Hot-encoding\n",
        "\n",
        "    x = np.array(x)\n",
        "    inp = x.reshape(1, inp_chars, num_characters)\n",
        "\n",
        "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    d = tokenizer.index_word[pred.argmax(axis=1)[0]] # получаем ответ в символьном представлении\n",
        "\n",
        "    inp_str += d # дописываем строку\n",
        "\n",
        "  return inp_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-vxdO-dMijp",
        "outputId": "744e6651-f352-45ae-f90c-e6c7c1762598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "утренновтвве лу выйсопертгирой тоыетлизных тозулкинто п \n"
          ]
        }
      ],
      "source": [
        "res = buildPhrase(\"утренн\")\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lp6XvkoOYyH"
      },
      "source": [
        "# Слова\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 389,
      "metadata": {
        "id": "revghpcNPQSd"
      },
      "outputs": [],
      "source": [
        "with open('text.txt', 'r', encoding='utf-8') as f:\n",
        "    texts = f.read()\n",
        "    texts = texts.replace('\\ufeff', '')\n",
        "\n",
        "maxWordsCount = 1000\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
        "                       lower=True, split=' ', char_level=False)\n",
        "tokenizer.fit_on_texts([texts])\n",
        "\n",
        "dist = list(tokenizer.word_counts.items())\n",
        "data = tokenizer.texts_to_sequences([texts])\n",
        "res = keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "\n",
        "data = tokenizer.texts_to_sequences([texts])\n",
        "res = np.array( data[0] )\n",
        "\n",
        "inp_words = 3\n",
        "n = res.shape[0]-inp_words\n",
        "\n",
        "X = np.array([res[i:i+inp_words] for i in range(n)])\n",
        "Y = keras.utils.to_categorical(res[inp_words:], num_classes=maxWordsCount)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 390,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc8dLHkSQ9Nr",
        "outputId": "3943da98-5b52-424b-db37-e6817490206e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 3, 256)            256000    \n",
            "                                                                 \n",
            " simple_rnn_33 (SimpleRNN)   (None, 128)               49280     \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 1000)              129000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 434280 (1.66 MB)\n",
            "Trainable params: 434280 (1.66 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "52/52 [==============================] - 1s 7ms/step - loss: 6.8576 - accuracy: 0.0361\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 6.1921 - accuracy: 0.0559\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 5.7106 - accuracy: 0.0805\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 5.1905 - accuracy: 0.1454\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 4.5403 - accuracy: 0.2013\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 3.8710 - accuracy: 0.3450\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 3.2371 - accuracy: 0.4874\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 2.6576 - accuracy: 0.6022\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 2.1582 - accuracy: 0.6965\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 1.7358 - accuracy: 0.7728\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 1.3870 - accuracy: 0.8401\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 1.1059 - accuracy: 0.8954\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.8840 - accuracy: 0.9207\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.7114 - accuracy: 0.9441\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5744 - accuracy: 0.9633\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.9742\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.9802\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.3186 - accuracy: 0.9814\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.2682 - accuracy: 0.9862\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.2289 - accuracy: 0.9874\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.1954 - accuracy: 0.9880\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.1711 - accuracy: 0.9868\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.1506 - accuracy: 0.9892\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.1334 - accuracy: 0.9886\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 1s 10ms/step - loss: 0.1192 - accuracy: 0.9868\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 1s 10ms/step - loss: 0.1067 - accuracy: 0.9880\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0973 - accuracy: 0.9880\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0901 - accuracy: 0.9886\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0765 - accuracy: 0.9862\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9874\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0669 - accuracy: 0.9886\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0633 - accuracy: 0.9886\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9886\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0561 - accuracy: 0.9868\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9880\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0508 - accuracy: 0.9880\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9868\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9892\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0456 - accuracy: 0.9868\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0433 - accuracy: 0.9892\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9862\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9886\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0382 - accuracy: 0.9886\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9880\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9868\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9886\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0341 - accuracy: 0.9874\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9874\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.0322 - accuracy: 0.9892\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(maxWordsCount, 256, input_length = inp_words))\n",
        "model.add(SimpleRNN(128, activation='tanh'))\n",
        "model.add(Dense(maxWordsCount, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "history = model.fit(X, Y, batch_size=32, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(texts, str_len = 10):\n",
        "  res = texts\n",
        "  data = tokenizer.texts_to_sequences([texts])[0]\n",
        "  for i in range(str_len):\n",
        "    x = data[i: i+inp_words]\n",
        "    inp = np.expand_dims(x, axis=0)\n",
        "    pred = model.predict( inp )\n",
        "    indx = pred.argmax(axis=1)[0]\n",
        "    data.append(indx)\n",
        "    res += \" \" + tokenizer.index_word[indx]\n",
        "  return res\n",
        "\n",
        "for i in range(1):\n",
        "  x = keras.utils.to_categorical(data[i: i+inp_words], num_classes=maxWordsCount)\n",
        "\n",
        "res = buildPhrase(\"позитив добавляет годы\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfiBeREbC3jH",
        "outputId": "43baae78-6cf3-4c0b-d856-5f593130f5da"
      },
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 205ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "позитив добавляет годы свои вашей жизни лучшей двигаться прагматично оставайся вы узнаете других\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
